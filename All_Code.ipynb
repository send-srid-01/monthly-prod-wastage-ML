{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Sandman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Pool_Nm</th>\n",
       "      <th>RPT_DATE</th>\n",
       "      <th>DAYS_PROD</th>\n",
       "      <th>BBLS_OIL_COND</th>\n",
       "      <th>OIL_RUNS</th>\n",
       "      <th>BBLS_WTR</th>\n",
       "      <th>MCF_GAS</th>\n",
       "      <th>MCF_SOLD</th>\n",
       "      <th>FLARED</th>\n",
       "      <th>VENTED</th>\n",
       "      <th>Dt_Treat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33525</th>\n",
       "      <td>33023008570000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2013-09-01 00:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>6427</td>\n",
       "      <td>6354</td>\n",
       "      <td>3117</td>\n",
       "      <td>6743</td>\n",
       "      <td>0</td>\n",
       "      <td>6743</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69165</th>\n",
       "      <td>33025012720000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2013-07-01 00:00:00</td>\n",
       "      <td>31</td>\n",
       "      <td>2178</td>\n",
       "      <td>2159</td>\n",
       "      <td>1595</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-06-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141340</th>\n",
       "      <td>33053038470000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>7436</td>\n",
       "      <td>7587</td>\n",
       "      <td>5247</td>\n",
       "      <td>6945</td>\n",
       "      <td>0</td>\n",
       "      <td>6756</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170046</th>\n",
       "      <td>33055001640000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2014-04-01 00:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>2599</td>\n",
       "      <td>2620</td>\n",
       "      <td>588</td>\n",
       "      <td>2314</td>\n",
       "      <td>1906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226910</th>\n",
       "      <td>33061020760000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>5076</td>\n",
       "      <td>4999</td>\n",
       "      <td>2564</td>\n",
       "      <td>2907</td>\n",
       "      <td>0</td>\n",
       "      <td>2861</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76218</th>\n",
       "      <td>33025015040000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1400</td>\n",
       "      <td>1906</td>\n",
       "      <td>424</td>\n",
       "      <td>1481</td>\n",
       "      <td>0</td>\n",
       "      <td>1481</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197068</th>\n",
       "      <td>33061012240000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2010-09-01 00:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>9894</td>\n",
       "      <td>9647</td>\n",
       "      <td>8161</td>\n",
       "      <td>3766</td>\n",
       "      <td>0</td>\n",
       "      <td>3766</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-07-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>33007015420000</td>\n",
       "      <td>DUPEROW</td>\n",
       "      <td>2014-02-01 00:00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>565</td>\n",
       "      <td>667</td>\n",
       "      <td>5474</td>\n",
       "      <td>928</td>\n",
       "      <td>928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47548</th>\n",
       "      <td>33025008480000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2010-05-01 00:00:00</td>\n",
       "      <td>31</td>\n",
       "      <td>4423</td>\n",
       "      <td>4085</td>\n",
       "      <td>1877</td>\n",
       "      <td>1112</td>\n",
       "      <td>0</td>\n",
       "      <td>1112</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-10-10 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102916</th>\n",
       "      <td>33053029690000</td>\n",
       "      <td>BAKKEN</td>\n",
       "      <td>2011-04-01 00:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>2212</td>\n",
       "      <td>2304</td>\n",
       "      <td>233</td>\n",
       "      <td>3095</td>\n",
       "      <td>2299</td>\n",
       "      <td>795</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   API  Pool_Nm             RPT_DATE  DAYS_PROD  \\\n",
       "33525   33023008570000   BAKKEN  2013-09-01 00:00:00         30   \n",
       "69165   33025012720000   BAKKEN  2013-07-01 00:00:00         31   \n",
       "141340  33053038470000   BAKKEN  2013-12-01 00:00:00         27   \n",
       "170046  33055001640000   BAKKEN  2014-04-01 00:00:00         30   \n",
       "226910  33061020760000   BAKKEN  2013-01-01 00:00:00         24   \n",
       "76218   33025015040000   BAKKEN  2014-05-01 00:00:00         12   \n",
       "197068  33061012240000   BAKKEN  2010-09-01 00:00:00         30   \n",
       "1888    33007015420000  DUPEROW  2014-02-01 00:00:00         28   \n",
       "47548   33025008480000   BAKKEN  2010-05-01 00:00:00         31   \n",
       "102916  33053029690000   BAKKEN  2011-04-01 00:00:00         30   \n",
       "\n",
       "        BBLS_OIL_COND  OIL_RUNS  BBLS_WTR  MCF_GAS  MCF_SOLD  FLARED  VENTED  \\\n",
       "33525            6427      6354      3117     6743         0    6743       0   \n",
       "69165            2178      2159      1595     1991      1991       0       0   \n",
       "141340           7436      7587      5247     6945         0    6756       0   \n",
       "170046           2599      2620       588     2314      1906       0       0   \n",
       "226910           5076      4999      2564     2907         0    2861       0   \n",
       "76218            1400      1906       424     1481         0    1481       0   \n",
       "197068           9894      9647      8161     3766         0    3766       0   \n",
       "1888              565       667      5474      928       928       0       0   \n",
       "47548            4423      4085      1877     1112         0    1112       0   \n",
       "102916           2212      2304       233     3095      2299     795       0   \n",
       "\n",
       "                   Dt_Treat  \n",
       "33525   2012-11-08 00:00:00  \n",
       "69165   2011-06-04 00:00:00  \n",
       "141340  2012-11-07 00:00:00  \n",
       "170046  2012-08-08 00:00:00  \n",
       "226910  2012-09-15 00:00:00  \n",
       "76218   2013-05-16 00:00:00  \n",
       "197068  2010-07-23 00:00:00  \n",
       "1888    2013-05-23 00:00:00  \n",
       "47548   2009-10-10 00:00:00  \n",
       "102916  2009-03-01 00:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('monthly-production.csv')\n",
    "data1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = data1[data1.Pool_Nm == 'MADISON']\n",
    "d2 = data1[data1.Pool_Nm == 'TYLER']\n",
    "d3 = data1[data1.Pool_Nm == 'BIRDBEAR']\n",
    "d4 = data1[data1.Pool_Nm == 'BAKKEN']\n",
    "d5 = data1[data1.Pool_Nm == 'RED RIVER']\n",
    "d6 = data1[data1.Pool_Nm == 'DUPEROW']\n",
    "d7 = data1[data1.Pool_Nm == 'STONEWALL']\n",
    "d8 = data1[data1.Pool_Nm == 'THREE FORKS']\n",
    "d9 = data1[data1.Pool_Nm == 'HEATH']\n",
    "d10 = data1[data1.Pool_Nm == 'SPEARFISH/MADISON']\n",
    "d11 = data1[data1.Pool_Nm == 'ORDOVICIAN']\n",
    "d12 = data1[data1.Pool_Nm == 'PIERRE']\n",
    "d13 = data1[data1.Pool_Nm == 'MIDALE/NESSON']\n",
    "d14 = data1[data1.Pool_Nm == 'WINNIPEGOSIS']\n",
    "d15 = data1[data1.Pool_Nm == 'MINNELUSA']\n",
    "d16 = data1[data1.Pool_Nm == 'SILURIAN']\n",
    "d17 = data1[data1.Pool_Nm == 'LODGEPOLE']\n",
    "d18 = data1[data1.Pool_Nm == 'BAKKEN/THREE FORKS']\n",
    "d19 = data1[data1.Pool_Nm == 'DEVONIAN']\n",
    "d20 = data1[data1.Pool_Nm == 'SANISH']\n",
    "d21 = data1[data1.Pool_Nm == 'UnknownXML']\n",
    "d22 = data1[data1.Pool_Nm == 'MISSION CANYON']\n",
    "d_list = [d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "y = data1.drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 2)\n",
    "classifier = MultiOutputRegressor(knn, n_jobs = -1)\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.score(X_train,y_train)\n",
    "#Returns a score of 0.8106289784183698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "dtc = DecisionTreeRegressor\n",
    "classifier = MultiOutputRegressor(dtc, n_jobs = -1)\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.score(X_train,y_train)\n",
    "#Returns error, see paper for issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "rfc = RandomForestRegressor()\n",
    "classifier = MultiOutputRegressor(rfc, n_jobs = -1)\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.score(X_train,y_train)\n",
    "#Returns a score of 0.9398846155864967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def multi_run_knn_2(list):\n",
    "    score_list = []\n",
    "    for i in range(len(list)):\n",
    "        X = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "        y = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        knn = KNeighborsRegressor(n_neighbors = 2)\n",
    "        classifier = MultiOutputRegressor(knn, n_jobs = -1)\n",
    "\n",
    "        sum_score = 0\n",
    "        for i in range(50): #Run 50 times to get an average score\n",
    "            classifier.fit(X_train, y_train)\n",
    "            i_score = classifier.score(X_test, y_test)\n",
    "        sum_score += i_score\n",
    "\n",
    "    score = sum_score/50\n",
    "    score_list.append(score)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "knn_2 = multi_run_knn_2(d_list)\n",
    "knn_2\n",
    "'''Returns array [0.6245446050787142,\n",
    " 0.8355076187437787,\n",
    " 0.3806179165181526,\n",
    " 0.41573656512548834,\n",
    " 0.8799898075080087,\n",
    " 0.786363910610263,\n",
    " -4.351236927423947,\n",
    " 0.8844452373783233,\n",
    " 0.7435262253930505,\n",
    " 0.8036912250872845,\n",
    " 0.8916928334292328,\n",
    " 0.9786036036036029,\n",
    " 0.625009316883461,\n",
    " 0.48270343787875575,\n",
    " 0.7593691122814752,\n",
    " 0.5423877885951075,\n",
    " 0.8049239503681678,\n",
    " 0.5562603646194377,\n",
    " 0.17085078150232844,\n",
    " 0.5515240490360431,\n",
    " 2,\n",
    " 1.0] See paper for value of 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def multi_run_knn_1(list):\n",
    "    score_list = []\n",
    "    for i in range(len(list)):\n",
    "        X = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "        y = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        knn = KNeighborsRegressor(n_neighbors = 1)\n",
    "        classifier = MultiOutputRegressor(knn, n_jobs = -1)\n",
    "\n",
    "        sum_score = 0\n",
    "        for i in range(50): #Run 50 times to get an average score\n",
    "            classifier.fit(X_train, y_train)\n",
    "            i_score = classifier.score(X_test, y_test)\n",
    "        sum_score += i_score\n",
    "\n",
    "    score = sum_score/50\n",
    "    score_list.append(score)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "knn_1 = multi_run_knn_2(d_list)\n",
    "knn_1\n",
    "'''Returns array [0.5688257596832466,\n",
    " 0.727053292684112,\n",
    " 0.6177350393767604,\n",
    " 0.2540630818081145,\n",
    " 0.7862717999147432,\n",
    " 0.33372942281187834,\n",
    " 0.5150536072793843,\n",
    " 0.7148412510845387,\n",
    " 0.6296541088345444,\n",
    " 0.678946546817861,\n",
    " 0.9672562185371821,\n",
    " 0.9120370370370375,\n",
    " 0.5851430510458657,\n",
    " 0.9762275956804083,\n",
    " -4.619248143241125,\n",
    " 0.47220263546442703,\n",
    " 0.5048483088665707,\n",
    " 0.372894403452236,\n",
    " -2.865302924690421,\n",
    " 0.4517202018517142,\n",
    " 2,\n",
    " 1.0] See paper for value of 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def multi_run_dtc_mse(list):\n",
    "    score_list = []\n",
    "    for i in range(len(list)):\n",
    "        X = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "        y = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        dtc_mse = DecisionTreeRegressor()\n",
    "        classifier = MultiOutputRegressor(dtc_mse, n_jobs = -1)\n",
    "\n",
    "        sum_score = 0\n",
    "        for i in range(50): #Run 50 times to get an average score\n",
    "            classifier.fit(X_train, y_train)\n",
    "            i_score = classifier.score(X_test, y_test)\n",
    "            sum_score += i_score\n",
    "\n",
    "        score = sum_score/50\n",
    "        score_list.append(score)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "dtc_mse = multi_run_dtc_mse(d_list)\n",
    "dtc_mse\n",
    "'''Returns array [0.6349743245204358,\n",
    " 0.6845140000387384,\n",
    " 0.7344100981804463,\n",
    " 0.20981263074734954,\n",
    " 0.9151379635405559,\n",
    " -0.423499187825443,\n",
    " -0.42422331779315764,\n",
    " 0.2518507899961422,\n",
    " 0.9843072702331965,\n",
    " 0.6004347088642841,\n",
    " 0.966828907037653,\n",
    " 1.0,\n",
    " 0.7193343111617204,\n",
    " 0.9709855750955587,\n",
    " 1.0,\n",
    " 0.44983784831113227,\n",
    " 0.33213751666063673,\n",
    " 0.5742996890545532,\n",
    " -0.30057127534829226,\n",
    " 0.49380419446536833,\n",
    " 2,\n",
    " 0.666666666666667] See paper for value of 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def multi_run_dtc_mae(list):\n",
    "    score_list = []\n",
    "    for i in range(len(list)):\n",
    "        X = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "        y = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        dtc_mae = DecisionTreeRegressor(criterion ='mae')\n",
    "        classifier = MultiOutputRegressor(dtc_mse, n_jobs = -1)\n",
    "\n",
    "        sum_score = 0\n",
    "        for i in range(50): #Run 50 times to get an average score\n",
    "            classifier.fit(X_train, y_train)\n",
    "            i_score = classifier.score(X_test, y_test)\n",
    "            sum_score += i_score\n",
    "\n",
    "        score = sum_score/50\n",
    "        score_list.append(score)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "dtc_mae = multi_run_dtc_mae(d_list)\n",
    "dtc_mae\n",
    "'''Returns array [0.7226022187842153,\n",
    "0.6471157434836408,\n",
    "0.6453043311580304,\n",
    "2,\n",
    "0.8285086955915067,\n",
    "0.5173777797798154,\n",
    "0.34860216873578853,\n",
    "0.7488838376241039,\n",
    "0.5389753968786264,\n",
    "0.7009546671078946,\n",
    "0.8648783983900366,\n",
    "1.0,0.7381772436465354,\n",
    "0.006548986531229965,\n",
    "-1.0834037762738016,\n",
    "0.5068015703376421,\n",
    "0.7556856228401944,\n",
    "0.49604231929614384,\n",
    "0.40858831907106286,\n",
    "0.4234659196523564,\n",
    "2,\n",
    "1.0] See paper for value of 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def multi_run_rfr_mse(list):\n",
    "    score_list = []\n",
    "    for i in range(len(list)):\n",
    "        X = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "        y = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        rfr_mse = RandomForestRegressor()\n",
    "        classifier = MultiOutputRegressor(rfr_mse, n_jobs = -1)\n",
    "\n",
    "        sum_score = 0\n",
    "        for i in range(50): #Run 50 times to get an average score\n",
    "            classifier.fit(X_train, y_train)\n",
    "            i_score = classifier.score(X_test, y_test)\n",
    "            sum_score += i_score\n",
    "\n",
    "        score = sum_score/50\n",
    "        score_list.append(score)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "rfr_mse = multi_run_rfr_mse(d_list)\n",
    "rfr_mse\n",
    "'''Returns array [0.7975728933656653,\n",
    "0.7491376733914002,\n",
    "0.6563816561127157,\n",
    "0.577954169365711,\n",
    "0.9540219957670919,\n",
    "0.8569672679783986,\n",
    "0.616892498731899,\n",
    "-2.708699464342708,\n",
    "0.7576933894471644,\n",
    "0.7924890255918052,\n",
    "0.9619620371249041,\n",
    "1.0,\n",
    "0.7110633130411644,\n",
    "0.6135267841268898,\n",
    "1.0,\n",
    "0.5533520429148342,\n",
    "0.8048702763865071,\n",
    "0.6354906128795269,\n",
    "0.472115589437678,\n",
    "0.7297427594643265,\n",
    "2,\n",
    "0.6666666666666666] See paper for value of 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def multi_run_rfr_mae(list):\n",
    "    score_list = []\n",
    "    for i in range(len(list)):\n",
    "        X = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "        y = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        rfr_mae = RandomForestRegressor(criterion = 'mae')\n",
    "        classifier = MultiOutputRegressor(rfr_mae, n_jobs = -1)\n",
    "\n",
    "        sum_score = 0\n",
    "        for i in range(50): #Run 50 times to get an average score\n",
    "            classifier.fit(X_train, y_train)\n",
    "            i_score = classifier.score(X_test, y_test)\n",
    "            sum_score += i_score\n",
    "\n",
    "        score = sum_score/50\n",
    "        score_list.append(score)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "rfr_mae = multi_run_rfr_mae(d_list)\n",
    "rfr_mae\n",
    "'''Returns array [0.5383007401579571,\n",
    "0.7780733883624369,\n",
    "0.7012608293656157,\n",
    "2,0.84364087848968,\n",
    "0.5714991471621426,\n",
    "0.36178717871898985,\n",
    "0.7274068626791199,\n",
    "-3.3294055242692413,\n",
    "0.7662617129295092,\n",
    "0.9336453092774336,\n",
    "0.6666666666666666,\n",
    "0.3555912625033811,\n",
    "0.6144494556281996,\n",
    "1.0,\n",
    "0.6081516618342633,\n",
    "0.8318514430070859,\n",
    "0.67658763262201,\n",
    "0.46320539995405596,\n",
    "0.6759782628685406,\n",
    "2,\n",
    "1.0] See paper for value of 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_run_nn(list):\n",
    "\n",
    "    def get_model(n_inputs, n_outputs):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, input_dim = n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "        model.add(Dense(n_outputs))\n",
    "        model.compile(loss='mae', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    r2_list_1 = []\n",
    "    r2_list_2 = []\n",
    "    r2_list_3 = []\n",
    "    for i in range(len(list)):\n",
    "        X = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'FLARED', 'VENTED', 'MCF_SOLD', 'BBLS_WTR' ])\n",
    "        y = list[i].drop(columns=['API','Pool_Nm','RPT_DATE', 'Dt_Treat', 'MCF_SOLD', 'DAYS_PROD', 'BBLS_OIL_COND', 'OIL_RUNS', 'MCF_GAS'])\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        model.fit(X_train, y_train, verbose = 0, epochs = 50)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = y_pred.round()\n",
    "        y_test = np.asarray(y_test)\n",
    "\n",
    "        r2_1 = r2_score(y_test[:,0], y_pred[:,0])\n",
    "        r2_2 = r2_score(y_test[:,1], y_pred[:,1])\n",
    "        r2_3 = r2_score(y_test[:,2], y_pred[:,2])\n",
    "    \n",
    "        r2_list_1.append(r2_1)\n",
    "        r2_list_2.append(r2_2)\n",
    "        r2_list_3.append(r2_3)\n",
    "\n",
    "    return r2_list_1, r2_list_2, r2_list_3\n",
    "\n",
    "r2_1, r2_2, r2_3 = multi_run_nn(d_list)\n",
    "'''Returns 3 arrays\n",
    "r2_1 = [0.07337855804275151, -0.49732436741224895, -0.1538186831645858, 0.18819403968734105, -0.1348537684107416, -0.06824171519814515, -0.45541148509334306, -0.878399252965234, -1.9340801378716073, -0.9616736375616324, -0.3252111976336485, -0.2837837837837831, -2.5041975998877395, -0.3052340625758101, -0.07130667793514145, -0.30878604637407925, -0.5268222885516274, -0.14790008911690933, -1.1800166704488753, -0.16580346378898025, 2, 1.0]\n",
    "r2_2 = [-0.009347204952288468, -0.05740536230372717, -0.03605163613669893, 0.2631464332349892, 0.18441338020453324, -0.06687801771902557, -0.01648334451751121, -0.08344617716875113, 1.0, 0.08005691774380252, 1.0, 0.0, 0.0, -0.02032307127497779, 0.0, -0.0180625366708147, -0.07073782573611398, -0.22786014552510725, -0.05195127516629561, -0.20726033838688807, 2, 1.0]\n",
    "r2_3 = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2, 1.0]\n",
    "See paper for value of 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['KNN', 'DTR', 'RFR']\n",
    "vals = [0.8106289784183698,0,0.9398846155864967]\n",
    "plt.bar(labels,vals)\n",
    "plt.title('Comparing Unsorted Models R^2 values')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R^2 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,23,1)\n",
    "plt.scatter(x,r2_1, label ='Neural Network')\n",
    "plt.scatter(x,dtc_mse, label = 'DTR, MSE')\n",
    "plt.scatter(x,dtc_mae, label = 'DTR, MAE')\n",
    "plt.scatter(x,knn_1, label='KNN, 1 Neighbor')\n",
    "plt.scatter(x,knn_2, label='KNN, 2 Neighbor')\n",
    "plt.scatter(x, rfc_mse, label = 'RFR, MSE')\n",
    "plt.scatter(x, rfc_mae, label = 'RFR, MAE')\n",
    "plt.title('Comparing R^2 values for Amount of Water Used')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,r2_2, label ='Neural Network')\n",
    "plt.scatter(x,dtc_mse, label = 'DTR, MSE')\n",
    "plt.scatter(x,dtc_mae, label = 'DTR, MAE')\n",
    "plt.scatter(x,knn_1, label='KNN, 1 Neighbor')\n",
    "plt.scatter(x,knn_2, label='KNN, 2 Neighbor')\n",
    "plt.scatter(x, rfc_mse, label = 'RFR, MSE')\n",
    "plt.scatter(x, rfc_mae, label = 'RFR, MAE')\n",
    "plt.title('Comparing R^2 values for Amount of Product Flared')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,r2_3, label ='Neural Network')\n",
    "plt.scatter(x,dtc_mse, label = 'DTR, MSE')\n",
    "plt.scatter(x,dtc_mae, label = 'DTR, MAE')\n",
    "plt.scatter(x,knn_1, label='KNN, 1 Neighbor')\n",
    "plt.scatter(x,knn_2, label='KNN, 2 Neighbor')\n",
    "plt.scatter(x, rfc_mse, label = 'RFR, MSE')\n",
    "plt.scatter(x, rfc_mae, label = 'RFR, MAE')\n",
    "plt.title('Comparing R^2 values for Amount of Product Vented')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    bak_1 = r2_1[0]\n",
    "    bak_2 = dtc_mae[3]\n",
    "    bak_3 = rfc_mse[3]\n",
    "    bak_4 = rfc_mae[3]\n",
    "    bak_5 = dtc_mse[3]\n",
    "    bak_6 = knn_1[3]\n",
    "    bak_7 = knn_2[3]\n",
    "\n",
    "labels = ['NN', 'DTC, MAE', 'RFR, MSE', 'RFR, MAE', 'DTC, MSE', 'KNN, 1 Neighbor', 'KNN, 2 Neighbor']\n",
    "vals = [bak_1, bak_2, bak_3, bak_4, bak_5, bak_6, bak_7]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.bar(labels,vals)\n",
    "plt.grid()\n",
    "plt.title('Comparing Sorted Models R^2 values for Bakken Formation, Predicting Water Usage')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R^2 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    bak_1 = r2_1[1]\n",
    "    bak_2 = dtc_mae[3]\n",
    "    bak_3 = rfc_mse[3]\n",
    "    bak_4 = rfc_mae[3]\n",
    "    bak_5 = dtc_mse[3]\n",
    "    bak_6 = knn_1[3]\n",
    "    bak_7 = knn_2[3]\n",
    "\n",
    "labels = ['NN', 'DTC, MAE', 'RFR, MSE', 'RFR, MAE', 'DTC, MSE', 'KNN, 1 Neighbor', 'KNN, 2 Neighbor']\n",
    "vals = [bak_1, bak_2, bak_3, bak_4, bak_5, bak_6, bak_7]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.bar(labels,vals)\n",
    "plt.grid()\n",
    "plt.title('Comparing Sorted Models R^2 values for Bakken Formation, Predicting Flaring')\n",
    "plt.ylabel('R^2 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    bak_1 = r2_1[2]\n",
    "    bak_2 = dtc_mae[3]\n",
    "    bak_3 = rfc_mse[3]\n",
    "    bak_4 = rfc_mae[3]\n",
    "    bak_5 = dtc_mse[3]\n",
    "    bak_6 = knn_1[3]\n",
    "    bak_7 = knn_2[3]\n",
    "\n",
    "labels = ['NN', 'DTC, MAE', 'RFR, MSE', 'RFR, MAE', 'DTC, MSE', 'KNN, 1 Neighbor', 'KNN, 2 Neighbor']\n",
    "vals = [bak_1, bak_2, bak_3, bak_4, bak_5, bak_6, bak_7]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.bar(labels,vals)\n",
    "plt.grid\n",
    "plt.title('Comparing Sorted Models R^2 values for Bakken Formation, Predicting Venting')\n",
    "plt.ylabel('R^2 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    nn_fail = 0\n",
    "    knn_1_fail = 0\n",
    "    knn_2_fail = 0\n",
    "    dtc_mae_fail = 0\n",
    "    dtc_mse_fail = 0\n",
    "    rfr_mae_fail = 0\n",
    "    rfr_mse_fail = 0\n",
    "\n",
    "    for j in range(3):\n",
    "        if r2_1[j] == 2:\n",
    "        nn_fail += 1\n",
    "\n",
    "    for k in range(len(knn_1)):\n",
    "        if knn_1[k] == 2:\n",
    "            knn_1_fail += 1\n",
    "        if knn_2[k] == 2:\n",
    "            knn_2_fail += 1 \n",
    "        if dtc_mae[k] == 2:\n",
    "            dtc_mae_fail += 1\n",
    "        if dtc_mse[k] == 2:\n",
    "            dtc_mse_fail += 1\n",
    "        if rfc_mae[k] == 2:\n",
    "            rfr_mae_fail += 1\n",
    "        if rfc_mse[k] == 2:\n",
    "            rfr_mse_fail += 1\n",
    "\n",
    "labels = ['NN', 'DTC, MAE', 'RFR, MSE', 'RFR, MAE', 'DTC, MSE', 'KNN, 1 Neighbor', 'KNN, 2 Neighbor']\n",
    "vals = [nn_fail, dtc_mae_fail, rfr_mse_fail, rfr_mae_fail, dtc_mse_fail, knn_1_fail, knn_2_fail]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.bar(labels, vals)\n",
    "plt.title('Graph comparing the number of failed/uncomputed R^2 scores per model')\n",
    "plt.ylabel('Number Of Fails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r2_1)):\n",
    "    if r2_1[i] == 2:\n",
    "        r2_1[i] = 0\n",
    "sum1 = 0\n",
    "for i in range(len(r2_1)):\n",
    "    sum1 += r2_1[i]\n",
    "sum1 = sum1/21\n",
    "sum1\n",
    "#Returns -0.34706185628784936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r2_2)):\n",
    "    if r2_2[i] == 2:\n",
    "        r2_2[i] = 0\n",
    "sum2 = 0\n",
    "for i in range(len(r2_2)):\n",
    "    sum2 += r2_2[i]\n",
    "sum2 = sum2/21\n",
    "sum2\n",
    "#Returns 0.09262681823918098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r2_3)):\n",
    "    if r2_3[i] == 2:\n",
    "        r2_3[i] = 0\n",
    "sum3 = 0\n",
    "for i in range(len(r2_3)):\n",
    "    sum3 += r2_3[i]\n",
    "sum3 = sum3/21\n",
    "sum3\n",
    "#Returns 0.6666666666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(knn_2)):\n",
    "    if knn_2[i] == 2:\n",
    "        knn_2[i] = 0\n",
    "sumk2 = 0\n",
    "for i in range(len(knn_2)):\n",
    "    sumk2 += knn_2[i]\n",
    "sumk2 = sumk2/21\n",
    "sumk2\n",
    "#Returns 0.5257639387432165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(knn_1)):\n",
    "    if knn_1[i] == 2:\n",
    "        knn_1[i] = 0\n",
    "sumk1 = 0\n",
    "for i in range(len(knn_1)):\n",
    "    sumk1 += knn_1[i]\n",
    "sumk1 = sumk1/21\n",
    "sumk1\n",
    "#Returns 0.21828344258567037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rfc_mse)):\n",
    "    if rfc_mse[i] == 2:\n",
    "        rfc_mse[i] = 0\n",
    "sumrmse = 0\n",
    "for i in range(len(rfc_mse):\n",
    "    sumrmse += rfc_mse[i]\n",
    "sumrmse = sumrmse/21\n",
    "sumrmse\n",
    "#Returns 0.5809143422596019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dtc_mse)):\n",
    "    if dtc_mse[i] == 2:\n",
    "        dtc_mse[i] = 0\n",
    "sumdmse = 0\n",
    "for i in range(len(dtc_mse)):\n",
    "    sumdmse += dtc_mse[i]\n",
    "sumdmse = sumdmse/21\n",
    "sumdmse\n",
    "#Returns 0.4460243534388918"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
